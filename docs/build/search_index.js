var documenterSearchIndex = {"docs":
[{"location":"#AutoLandmarking.jl-Documentation","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.jl Documentation","text":"","category":"section"},{"location":"#Data-loading","page":"AutoLandmarking.jl Documentation","title":"Data loading","text":"","category":"section"},{"location":"","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.jl Documentation","text":"load_imgs(path, dims, numerical)\r\nread_landmarks(path, num_landmarks, group)","category":"page"},{"location":"#AutoLandmarking.load_imgs-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.load_imgs","text":"load_imgs(path, dims, numerical)\n\nReads all the volume images of an entire directory. Data must be stored as follows: The required input \"path\" is the path to a directory containing one sub-directory for every volume that has to be read. Each sub-directory contains the images making up one volume in .tif format. if the image names contain alphabetical characters (e.g. image001.tif, image002.tif ect.) the variable \"numerical\" has to be set to false, if the image names are just numerical values (e.g 1.tif, 2.tif, 3.tif, ect), it has to be set to true. Any file not ending in .tif will not be read.\n\nData will be stored in a 4D array [a x b c x n] with n being the number of sub-directories, a and b the resolution of the .tif images and c the number of images. The the resolution of the images has to be the same over all the volumes.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.read_landmarks-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.read_landmarks","text":"read_landmarks(path, num_landmarks, group)\n\nSpecific function to read avizo landmark data into an array. Reads all the files ending in .Ascii in the directory specified as \"path\". Data will be stored in a 2D array [c x n] with c being the number of individual 3D coordinates (30 coordinates in the case of 10 landmarks) and n being the number of landmark files read.\n\nThe variable Group specifies the group of landmarks in the Avizo file that has to be read (e.g \"@1\" in the case of group 1)\n\n\n\n\n\n","category":"method"},{"location":"#Data-augmentation","page":"AutoLandmarking.jl Documentation","title":"Data augmentation","text":"","category":"section"},{"location":"","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.jl Documentation","text":"flip_volume_front(x, y)\r\nflip_volume_side(x, y)\r\nmirror_vol(x, y)\r\nAutoLandmarking.flip_2D(x, y)\r\nAutoLandmarking.flip_3D(x, y)\r\njitter_3D(volumes, landmarks, padding)\r\nrotate_images(imgs, lms, deg)\r\nrotate_volumes(vols, lms, deg)","category":"page"},{"location":"#AutoLandmarking.flip_volume_front-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.flip_volume_front","text":"flip_volume_front(x, y)\n\nFlip a volume so that the longitudinal (x) axis becomes the vertical (z) axis and adjust the landmakr coordinates accordingly.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.flip_volume_side-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.flip_volume_side","text":"flip_volume_side(x, y)\n\nFlip a volume so that the lateral (y) axis becomes the vertical (z) axis and adjust the landmark coordinates accordingly.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.mirror_vol-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.mirror_vol","text":"function mirror_vol(x, y)\n\nA form of data augmentation. Mirrors a volume (exchanges x and y axis) and returns concatenation of original data and mirrored data.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.flip_2D-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.flip_2D","text":"flip_2D(x, y)\n\nTakes 2D images in a 4D tensor and landmark data in 2D tensor and returns the flipped (clockwise) images, aswell as the coordinates for the flipped images. only works on square images.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.flip_3D-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.flip_3D","text":"flip_3D(x, y)\n\nTakes 3D volumes in a 4D tensor and landmark data in 2D tensor and returns the flipped (clockwise) volumes, aswell as the coordinates for the flipped volumes.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.jitter_3D-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.jitter_3D","text":"jitter_3D(volumes, landmarks, padding)\n\nJitters around binarized volumes based on their corresponding x/y landmarks, so that the relevant object (smaller voxel value) will still be fully inside the volume but moved around randomly inside the volume.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.rotate_images-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.rotate_images","text":"rotate_images(img, lms, deg)\n\nTakes a 3d tensor [res1 x res1 x n] with n images and rotates all of them in a counterclockwise direction around their center by deg degrees. Will adjust the 2d coordinates of the landmark array [coords x n]. Returns rotated images and adjusted landmarks.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.rotate_volumes-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.rotate_volumes","text":"rotate_volumes(vols, lms, deg)\n\nTakes a 4d tensor [res1 x res2 x res3 x n] with n volumes and rotates all of them around their center by deg degrees. The rotation is along the z-axis, so the z-coordinates will not be affected. x- and y coordinates of the landmark array [coords x n] will be adjusted. Returns rotated volumes and adjusted landmarks.\n\n\n\n\n\n","category":"method"},{"location":"#Data-preparation","page":"AutoLandmarking.jl Documentation","title":"Data preparation","text":"","category":"section"},{"location":"","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.jl Documentation","text":"swap_xy(lms)\r\ntrain_test_split_3d(X, y, train_ratio)\r\nregular_train_test_split_3d(X, y)\r\nlandmark_to_surface(volumes, landmarks, radius)\r\nimage_gradients(x)\r\nalign_principal(volumes, landmarks, output_size::Int)\r\nresize_relevant(vols, lms, out_size)\r\ntranslate_lms_back(lms, reconstruction_array)\r\nchoose_dims(y, dims)\r\nAutoLandmarking.give_z_value(x)\r\nAutoLandmarking.depth_map(x)\r\ndepth_map_all_sides(x)","category":"page"},{"location":"#AutoLandmarking.swap_xy-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.swap_xy","text":"swap_xy(lms)\n\nSwaps x and y coordinates of a landmark array.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.train_test_split_3d-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.train_test_split_3d","text":"train_test_split_3d(X, y, train_ratio)\n\nRandomly split features and labels with ratio 'train_ratio' and return training and testing set. Takes a 5d tensor as X.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.regular_train_test_split_3d-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.regular_train_test_split_3d","text":"regular_train_test_split_3d(X, y)\n\nsplit features and labels so that every fifth entry in the original dataset is in the testin set (80/20 split) and return training and testing set. Takes a 5d tensor as X.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.landmark_to_surface-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.landmark_to_surface","text":"landmark_to_surface(volumes, landmarks, radius)\n\nMoves landmarks that are not already on the volume to the closest point to them on the surface of the volume.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.image_gradients-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.image_gradients","text":"image_gradients(x)\n\nAdds the sum of the image gradients in x and y direction for each channel of each image in a 4-dimensional tensor as a new channel.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.align_principal-Tuple{Any,Any,Int64}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.align_principal","text":"align_principal(volumes, landmarks, output_size)\n\nAligns all volumes in tensor \"volumes\" along their principal axis (new z-axis) and transforms respective landmark data alongside. The output size can be specified with outputsize (a cube with size outputsize^3 will be returned), but must be large enough to contain the largest aligned volume. a median filter will be applied to handle caused by transformation. Also returns a reconstruction array used to translate predicted landmarks back to their original volume.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.resize_relevant-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.resize_relevant","text":"resize_relevant(vols, lms, out_size)\n\nTakes the output from align_principal and resizes the relevant part (part containing the actual item) to a cube of specified size. Also returns the ratio between resized and original volume size. Adjusts landmarks.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.translate_lms_back-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.translate_lms_back","text":"translate_lms_back(lms, reconstruction_array)\n\nTakes an array of predicted landmarks and a reconstruction array as returned by align_principal() and translates the landmarks back to their respective original volume.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.choose_dims-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.choose_dims","text":"choose_dims(y, dims)\n\nchoose which dimensions of x,y and z should be included in the labels and return a new array containing only the specified dims.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.give_z_value-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.give_z_value","text":"give_z_value(x)\n\nsets every value outside of the actual volume to 0 and changes the voxel-values of every voxel within the volume to its corresponding z-coordinate. Returns the new tensor with all values normalized between -1 and 1.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.depth_map-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.depth_map","text":"make_elevation_map(x)\n\nReturns a 2d image for every volume in tensor x and sets the pixel values to the maximum value within each column of voxels in dimension z as returned by the function givezvalue().\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.depth_map_all_sides-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.depth_map_all_sides","text":"depth_map_all_sides(x)\n\nreturns a 4d image tensor with 6 channels per image, each representing a depthmap from one side of the volume.\n\n\n\n\n\n","category":"method"},{"location":"#Handling-and-utility","page":"AutoLandmarking.jl Documentation","title":"Handling and utility","text":"","category":"section"},{"location":"","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.jl Documentation","text":"AutoLandmarking.accuracy(x, y, modell, dimensions)\r\nAutoLandmarking.print_accuracy(x, y, modell, dimensions)\r\nAutoLandmarking.cost_whole_data_3D(x, y, cost)\r\nAutoLandmarking.cost_whole_data_2D(x, y, cost)\r\nAutoLandmarking.avg_accuracy_per_point(modelo, x, y, dims)\r\nAutoLandmarking.predict_single(model, x)\r\nAutoLandmarking.predict_set(X, model)\r\nAutoLandmarking.save_vols_to_folder(folder, vols, names)\r\nAutoLandmarking.array_to_lm_file(output_path, coordinates)","category":"page"},{"location":"#AutoLandmarking.accuracy-NTuple{4,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.accuracy","text":"accuracy(x, y, modell)\n\ncalculate euclidean distances between points in y and y' for all samples\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.print_accuracy-NTuple{4,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.print_accuracy","text":"print_accuracy(x, y, modell)\n\ncalculate and print euclidean distances between points in y and y' for all samples\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.cost_whole_data_3D-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.cost_whole_data_3D","text":"cost_whole_data(x, y)\n\ncalculates cost (as defined by function 'cost') over an entire 5d tensor containing 3d image data.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.cost_whole_data_2D-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.cost_whole_data_2D","text":"cost_whole_data_2D(x, y)\n\ncalculates cost (as defined by function 'cost') over an entire 4d tensor containing 2d image data.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.avg_accuracy_per_point-NTuple{4,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.avg_accuracy_per_point","text":"avg_accuracy_per_point(modelo, x, y, dims)\n\ncalculates average, min and max distance between predicted and actual landmarks.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.predict_single-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.predict_single","text":"predict_single(model, x)\n\nReturns the output of 'model' in testing mode given input x and applies the relu function to each output. Takes a single sample.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.predict_set-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.predict_set","text":"predict_set(X, model)\n\nReturns the output of 'model' in testing mode given input x and applies the relu function to each output. Takes multiple samples.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.save_vols_to_folder-Tuple{Any,Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.save_vols_to_folder","text":"save_vols_to_folder(folder, vols, names)\n\nSave a 4D tensor containing 3D volumes to a folder, each in its own sub folder,  in .tif format.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.array_to_lm_file-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.array_to_lm_file","text":"array_to_lm_file(output_path, coordinates)\n\nCreate an avizo landmark file (output_path) with one set of landmarks. The coordinates to these landmarks need to be passed in the form of a one-dimensional array as returned by a network when one volume is given as the input.\n\n\n\n\n\n","category":"method"},{"location":"#Outlier-detection","page":"AutoLandmarking.jl Documentation","title":"Outlier detection","text":"","category":"section"},{"location":"","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.jl Documentation","text":"AutoLandmarking.response_distribution(model, X, lms, samples)\r\nAutoLandmarking.to_3d_array(arr)\r\nAutoLandmarking.align_all(arr)\r\nAutoLandmarking.to_2d_array(arr)\r\nAutoLandmarking.mean_shape(arr)\r\nAutoLandmarking.proc_distance(ref, arr)\r\nAutoLandmarking.procrustes_distance_list(arr, names, exclude_highest=false)\r\nAutoLandmarking.align( x :: Matrix{Float64}, y :: Matrix{Float64} )","category":"page"},{"location":"#AutoLandmarking.response_distribution-NTuple{4,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.response_distribution","text":"response_distribution(model, X, samples)\n\nTakes one sample and returns a distribution of responses for this sample by setting the model to trainmode! and thus enabling the dropout layers.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.to_3d_array-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.to_3d_array","text":"to_3d_array(arr)\n\nTakes a 2D landmark array for 3 dimensions as input and outputs a 3D array with dimensions [npoints x 3 x nindividuals]\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.align_all-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.align_all","text":"align_all(arr)\n\nPerforms procrustes alignment on all the landmarks over all the individuals in a 3D landmark array as returned by the function to3darray().\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.to_2d_array-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.to_2d_array","text":"to_2d_array(arr)\n\nconverts a 3D landmark array to a 2D landmark array with dimensions [coordinates x individuals] where coordinates are x,y,z coordinates repeated as many times as there are landmarks.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.mean_shape-Tuple{Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.mean_shape","text":"mean_shape(arr)\n\nfinds the mean shape of all teh individuals in a 3D landmark array. Procrustes alignment should be performed before finding the mean.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.proc_distance-Tuple{Any,Any}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.proc_distance","text":"proc_distance(ref, arr)\n\nreturns the procrustes distances to a reference (e.g. the mean shape) for every individual in a 3D landmark array.\n\n\n\n\n\n","category":"method"},{"location":"#AutoLandmarking.procrustes_distance_list","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.procrustes_distance_list","text":"procrustes_distance_list(arr, names, exclude_highest=false)\n\nreturns the procrustes distances to a reference (e.g. the mean shape) for every individual in a 3D landmark array.\n\n\n\n\n\n","category":"function"},{"location":"#AutoLandmarking.align-Tuple{Array{Float64,2},Array{Float64,2}}","page":"AutoLandmarking.jl Documentation","title":"AutoLandmarking.align","text":"function align(x,y)\n\naligns two structures [sets of points in 3D space]. Solves the \"Procrustes\" problem. Structures are expected to be of the same size, and the correspondence is assumed from the vector indices.\n\nReturns x aligned, by performing the rigid body transformation [rotation and translation that minimizes the RMSD between x and y].\n\nx, y, and xnew (return) are matrices of dimensions (n,3) (n is the number of points, 3 is the dimension of the space).\n\nL. Martinez, Institute of Chemistry - University of Campinas Jan 04, 2019\n\n\n\n\n\n","category":"method"}]
}
